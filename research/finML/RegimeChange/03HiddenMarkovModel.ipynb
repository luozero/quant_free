{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bf4b6f5e4145250d",
   "metadata": {},
   "source": [
    "## Hidden Markov Modeling\n",
    "\n",
    "Hidden Markov Modeling is a probabilistic model that represents the distribution of observation sequences. HMM is the simplest dynamic Bayesian network and has proven to be a powerful model in many application fields including finance. HMM encapsulates important ideas of probabilistic modeling, so we will briefly examine it here. In particular, they provide insights into understanding hidden variables and switching. We have already dealt with neural network models using gating such as GRU, LSTM, and RNN. However, since these models are implicit modeling stages, they cannot be explicitly controlled as needed for regime changes in finance.\n",
    "Now, let's assume that the discrete state $s_t$ at time $t$ is not visible to the observer. Furthermore, we assume that the hidden state follows a Markov Process. This setup differs from mixture models which assume that hidden variables are iid. We assume that the observation $y_t$ at time $t$ is independent of states at all other times. Due to the Markov property, the joint probability of the state sequence $\\mathbf{s} := \\{s_t\\}_{i=1}^T$ and observation sequence $\\mathbf{y} = \\{y_t\\}_{t=1}^T$ can be obtained as the product of transition probability densities $p(s_t | s_{t-1})$.\n",
    "\n",
    "$$p(\\mathbf{s,y}) = p(s_1)p(y_1|s_1) \\prod_{t=2}^{T} p(s_t | s_{t-1})p(y_t|s_t)$$\n",
    "\n",
    "The figure below shows the Bayesian Network representing the conditional dependency relationship between observed and hidden variables in HMM. The conditional dependency relationship defines the edges of the graph between parent node $Y_t$ and child node $S_t$.\n",
    "\n",
    "First, we introduce the so-called forward and backward probabilities for all states $s_t \\in \\{1, \\dots, K\\}$ and all time points:\n",
    "\n",
    "$$F_t(s) := \\mathbb{P}(s_t = \\mathbf{s, y}_{1:t}), B_t(\\mathbf{s}) := p(\\mathbf{y}_{t+1:T} | s_t = s)$$\n",
    "\n",
    "Here, by convention, $B_T(s) = 1$. For all $t \\in \\{1,\\dots, T\\}$ and all $r,s \\in \\{1, \\dots, K\\}$, we obtain:\n",
    "\n",
    "$$\\mathbf{P}(s_t = s, \\mathbf{y}) = F_t(s)B_t(s)$$\n",
    "\n",
    "And by combining forward and backward probabilities, we can derive:\n",
    "\n",
    "$$\\mathbb{P}(s_{t-1} = r, s_t = s, \\mathbf{y}) = F_{t-1}(r)\\mathbb{P}(s_t = s | s_{t-1} = r)p(y_t | s_t = s)B_t(s)$$\n",
    "\n",
    "The forward-backward algorithm, also known as the Baum-Welch Algorithm, is an unsupervised learning algorithm for fitting HMMs that belongs to the class of EM algorithms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffdbfae35a47b95",
   "metadata": {},
   "source": [
    "### 1. Viterbi Algorithm\n",
    "\n",
    "In addition to finding the realization probability of specific hidden states, we can also find the most likely sequence realization. This sequence can be estimated using the Viterbi algorithm. Let's assume we observe a sequence of $T$ observations again.\n",
    "\n",
    "$$\\mathbf{y} = \\{y_1, \\dots, y_T\\}$$\n",
    "However, for each $1 \\leq t \\leq T, y_t \\in O$ where $O = \\{o_1, o_2, \\dots, o_N\\}, N \\in \\mathbb{N}$ is now in some observation space. For each $1 \\leq t \\leq T$, $y_t$ is driven by a (hidden) state $s_t \\in \\mathcal{S}$, where $\\mathcal{S} := \\{ \\int_1, \\dots, \\int_K\\}, K \\in \\mathbb{N}$ is some state space. For example, $y_t$ could be a corporate bond credit rating and $s_t$ could indicate some latent variable like the overall health of the relevant industry sector.\n",
    "\n",
    "Given $\\mathbf{y}$, what is the most likely sequence of hidden states?\n",
    "\n",
    "$$\\mathbf{x} = \\{x_1, x_2,\\ dots, x_T\\}$$\n",
    "\n",
    "To answer this problem, we introduce additional variables. First, we must be given an initial set of probabilities:\n",
    "\n",
    "$$\\mathcal{\\pi} = \\{\\pi_1, \\dots, \\pi_K\\}$$\n",
    "\n",
    "Thus $\\pi_i$ is the probability that $s_1 = \\int_i, 1 \\leq i \\leq K$. We also need to set up a transition matrix $A \\in \\mathbb{R}^{K \\times K}$ where element $A_{ij}, 1 \\leq i, j \\leq K$ is the transition probability from state $\\int_i$ to state $\\int_j$. Finally, we need an emission matrix $B \\in \\mathbb{R}^{K \\times N}$ where element $B_{ij}, 1 \\leq i \\leq K, 1 \\leq j \\leq N$ is the probability of observing $o_j$ from state $\\int_i$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960f84ec426643a1",
   "metadata": {},
   "source": [
    "The most probable state sequence $s$ that produces the observation sequence $y = \\{y_1, \\dots, y_T\\}$ satisfies the following recursive relation.\n",
    "Here, $V_{t,k}$ is the probability of the most likely state sequence $\\{s_1, \\dots, s_t\\}$ when $s_t = \\int_k$.\n",
    "\n",
    "$$V_{t,k} = \\mathbb{P}\\left(s_1, \\dots, s_t, y_1, \\dots, y_t| s_t = \\int_k\\right)$$\n",
    "\n",
    "The actual Viterbi Path can be obtained by tracking which state index $i$ was used in the second equation at each step. Now, let $\\xi(k, t)$ be a function that returns the value of $i$ used to calculate $V_{t,k}$ if $t > 1$ or $k$ if $t=1$. Then we have:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "s_T = & \\int_{\\arg \\max_{1 \\leq i \\leq K}} \\left( V_{T,k}\\right) \\\\ \n",
    "s_{t-1} = & \\int_{\\xi (s_t, t)}& \n",
    "\\end{align}\n",
    "$$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
